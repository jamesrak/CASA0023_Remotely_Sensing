<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>An Introduction to SAR</title>
    <meta charset="utf-8" />
    <meta name="author" content="Nutthaphol Rakratchatakul (James)" />
    <script src="libs/header-attrs-2.17/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# An Introduction to SAR
]
.subtitle[
## — the cloud penetration sensor —
]
.author[
### Nutthaphol Rakratchatakul (James)
]
.institute[
### Student ID: 21174510
]

---




# Sensor Summary

### Synthetic Aperture Radar (SAR)
- Using radar over optical remote sensing

- **Advantanges**

&gt; (+) Ability to capture data day or night

&gt; (+) See through clouds

&gt; (+) Weather independence by selecting proper frequency range

&gt; (+) Penetration through the vegetation
canopy and the soil

- (+/-) Sensitivity to structure

- **Disadvantanges**

&gt; (-) Information content is different than optical and sometimes difficult to interpret

- Variable resolution is 1 to 100 m
---

### SAR's Frequency and Wavelength

&lt;img src="images/SAR_bands.png" width="100%" style="display: block; margin: auto;" /&gt;
---

### Available Data in Earth Engine

**Sentinel-1 SAR GRD: C-band Synthetic Aperture Radar Ground Range Detected, log scaling**

.pull-left[
&lt;img src="images/COPERNICUS_S1_GRD_sample.png" width="100%" style="display: block; margin: auto;" /&gt;
]

.pull-right[
**The Sentinel-1** mission provides data from a dual-polarization C-band Synthetic Aperture Radar (SAR) instrument at 5.405GHz (C band). The collection is **updated daily**. New assets are ingested within two days after they become available.

- Each scene has one of 3 resolutions (10, 25 or 40 meters)
- 4 band combinations (single band VV or HH, and dual band VV+VH and HH+HV
)

[Source: GEE](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S1_GRD)
]
---

### Available Data in Earth Engine

**PALSAR-2 ScanSAR Level 2.2**

.pull-left[
&lt;img src="images/JAXA_ALOS_PALSAR-2_Level2_2_ScanSAR_sample.png" width="100%" style="display: block; margin: auto;" /&gt;
]

.pull-right[
**The 25 m PALSAR-2 ScanSAR** is normalized backscatter data of PALSAR-2 broad area observation mode with observation width of 350 km. The SAR imagery was ortho-rectificatied and slope corrected using the ALOS World 3D - 30 m (AW3D30) Digital Surface Model

[Source: GEE](https://developers.google.com/earth-engine/datasets/catalog/JAXA_ALOS_PALSAR-2_Level2_2_ScanSAR)
]
---

# SAR Applications
There are many applications using SAR data
&lt;img src="images/4-21_AustrailianSAR_BlogPic1.jpeg" width="80%" style="display: block; margin: auto;" /&gt;
[Source: Cherie Muleh 2021](https://www.l3harrisgeospatial.com/Learn/Blogs/Blog-Details/ArtMID/10198/ArticleID/24031/Enhancing-Situational-Awareness-with-SAR)
---

# SAR Applications
**Multi-Temporal SAR Data Large-Scale Crop Mapping Based on U-Net Model**
&lt;style type="text/css"&gt;
.left-column {
  float: left;
  width: 30%;
}
.right-column {
  float: right;
  width: 70%;
}
.small-font {
    font-size: 18px;
    padding: 0em 0em 0em 0em;
}
&lt;/style&gt;
.left-column[
&lt;img src="images/2-application-SAR-1.png" width="70%" style="display: block; margin: auto;" /&gt;
Source: [Sisi Wei 2019](https://www.mdpi.com/2072-4292/11/1/68)
]

.small-font[
This study presents a large-scale multispecies crop classification in Jilin, China. All of the pixels in SAR data were classified into four crops (including corn, peanut, soybeans, and rice,) and 4 non-crops (buildings, vegetation, water, and bare land). It achieved an overall accuracy of 85% as well as a Kappa coefficient of 0.82.
+ **Input**
  + Data: multi-temporal Sentinel-1 data (including dual-polarization SAR)
+ **Methodology**: Classification models were built classify 4 types of crops and also 4 types of non-crops by using convolutional neural network based architecture, such as U-Net and fully convolutional network (FCN).
+ **Comments**: It is good to see the researchers applying complex models such as deep learning models with the remote sensing data. Further improvement may include trying combining spectral data with SAR data. It is expected to improve the accuracy more or less. This is the reference for supporting this idea [Yinghui Quan 2020](https://www.mdpi.com/2072-4292/12/22/3801)
]

---

# Reflection

**Content**: Data generated by SAR are very useful, especially when using to gather data in some area covered with cloud. Although, it can be corrected by using data from the other timeframe, we may want to look what happens at the specific time that are full of clouds. Therefore, SAR with its feature to be able to see through clouds is quite useful in this case. Moreover, the frequency of data is also high. Moreover, I found that there are many data available in Google Earth Engine data catalog. This will be very useful for many researchers.

**Application**: As a computer science student, I am very happy to see how we can apply machine learning and deep learning methods with the applications in geography, environment and remote sensing. Recently, there are many more advanced models and architecture updating in every year. I would like to know more if the new advanced models can be applied and produced the useful outcomes or insight to the remote sensing field.

---

# References

- Enhancing Situational Awareness with SAR Data (no date) L3Harris Geospatial. Available at: [https://www.l3harrisgeospatial.com/Learn/Blogs/Blog-Details/ArtMID/10198/ArticleID/24031/Enhancing-Situational-Awareness-with-SAR](https://www.l3harrisgeospatial.com/Learn/Blogs/Blog-Details/ArtMID/10198/ArticleID/24031/Enhancing-Situational-Awareness-with-SAR) (Accessed: 2 February 2023).

- Earth Science Data Systems, N. (2020) What is Synthetic Aperture Radar?, Earthdata. Earth Science Data Systems, NASA. Available at: [https://www.earthdata.nasa.gov/learn/backgrounders/what-is-sar](https://www.earthdata.nasa.gov/learn/backgrounders/what-is-sar) (Accessed: 2 February 2023).
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
